\documentclass[12pt]{article}
\SweaveOpts{keep.source=TRUE, expand=FALSE}
%\VignetteIndexEntry{Trio Logic Regression and genotypic TDT}
%\VignetteDepends{trio}
%\VignettePackage{trio} 

\usepackage[margin=1.25in]{geometry}

\usepackage{color,colordvi}

\usepackage{amsmath,amstext}
%\usepackage{psfig}
\usepackage{natbib}
\usepackage{graphicx}
\RequirePackage[colorlinks=TRUE]{hyperref}
\hypersetup{linkcolor=black, menucolor=black, urlcolor=blue, citecolor=black}
%\usepackage[tight]{subfigure}
%\usepackage{lscape,rotating,setspace,tabularx}

\usepackage{fancyhdr}
\usepackage{fancyvrb}
\usepackage{setspace}
\usepackage{verbatim}
\usepackage{qingSweave}

\newcommand{\captionfonts}{\small}


%\setlength{\topmargin}{-15mm}
\setlength{\parskip}{2ex plus0.5ex minus0.2ex}

%\doublespacing
\parindent0em


\renewcommand{\familydefault}{cmss}
\renewcommand{\baselinestretch}{1.5}

\begin{document}

\thispagestyle{empty}

\bigskip

\begin{center}

{\LARGE \bf Preparing case-parent trio data\\[-6pt] and detecting disease-associated\\[12pt]
SNP interactions with \texttt{trio}}

\vspace*{0.9cm}

{\Large Qing Li, Holger Schwender, and Ingo Ruczinski}
\vspace*{0.1cm}
\end{center}
%\doublespace

\section{Introduction}

The \texttt{R} package \texttt{trio} contains functions for performing genotypic transmission
disequilibrium tests (gTDTs) for testing whether the distributions of individual SNPs \citep{schaid1996},
two-way interactions of SNPs \citep{cordell2002, cordell2004}, or interactions between SNPs and binary environmental variables 
differ between the cases, i.e.\ the children affected by a disease, and the pseudo-controls
derived from the parents' genotypes.

Furthrmore, \texttt{trio} provides functionalities relevant
for the analysis of case-parent trio data with {\it trio logic
regression} \citep{li2010}. Two major features are implemented in this package:
functions that aid in the transformation of the trio data from
standard linkage files (ped format) or genotype format into objects
suitable as input for trio logic regression, and a framework that
allows for the simulation of case-parent data, where the risk of
disease is specified by (higher order) SNP interactions. 

In Section \ref{read} of this vignette, it is shown how family-based data stored in a linkage/ped file can be read into
\texttt{R} and transformed into a format suitable for the application of the functions for performing the genotypic TDTs,
whereas Section \ref{testing} contains examples for the application of these gTDT functions to individual 
SNPs, two-way SNP interactions, and gene-environment interactions.

Section \ref{trio} is devoted to the steps relevant
for data processing, to derive a matrix suitable as
input for trio logic regression, starting from a linkage or genotype
file which possibly contains missing data and/or Mendelian errors. We
give some examples how missing data can be addressed using haplotype-based 
imputation. The haplotype information can be specified by the
user, or when this information is not readily available, automatically
inferred. The haplotype blocks are also relevant in the delineation of
the genotypes for the pseudo-controls, as the linkage disequilibrium
(LD) structure observed in the parents is taken into account in this
process. While this function is intended to generate complete case-pseudo-control 
data as input for trio logic regression, an option to
simply return the completed trio data is also available.

For the estimation of the haplotype structure that might be used in the
functions described in Section \ref{trio}, the \texttt{R} package \texttt{trio}
also contains functions for computing and plotting the pairwise LD values
and for detecting LD blocks. In Section \ref{getLD}, it is described how the
pairwise values of the LD measures $D^\prime$ and $r^2$ can be computed 
with the function \texttt{getLD()}, and how the $D^\prime$ values can be employed to
estimate haplotype blocks with the algorithm of \citet{gabriel2002}. 

Finally, Section \ref{simulation} of the vignette explains in more detail how to set
up simulations of case-parent trio data, where the risk of disease is
specified by SNP interactions. The most time-consuming step for
these types of simulations is the generation of mating tables and
the respective probabilities. The mating table information, however, can
be stored, which allows for fast simulations when replicates of the
case-parent trio data are generated.

\section{Preparing data for the genotypic TDTs}\label{read}

Case-parent trio data are typically stored in a ped file. 
The first six columns in such a ped file, which is also referred to as linkage file, 
identify the family structure of the data, and the
phenotype. It is assumed that only one phenotype variable (column 6)
is used. The object \texttt{trio.ped1}, available in the \texttt{R} package,
is an example of a data set in ped format. It contains information for 10 SNPs
in 100 trios. Besides the variables providing information on the
family structure and the phenotypes (columns 1--6), each SNP is
encoded in two variables denoting the alleles.

%chunk1
<<>>=
library(trio)
data(trio.data)
str(trio.ped1)
trio.ped1[1:10,1:12]
@

If not already available as data frame or matrix in the \texttt{R} workspace, 
trio data can be read into \texttt{R} using the function \texttt{read.pedfile()}.
If we, for example, assume that the working directory of the current \texttt{R} session contains a file called "pedfile.ped" 
(this file is actually not available in \texttt{trio}, we just assume that such a file exists in the working
directory), then this file can be read into \texttt{R} by calling

\begin{verbatim}
   > ped <- read.pedfile("pedfile.ped")
\end{verbatim}
If the arguments \texttt{coded} and \texttt{first.row} of \texttt{read.pedfile()}
are not specified by the user, \texttt{read.pedfile()} automatically tries to
figures out how the alleles in the ped file are coded, and whether the first row contains the SNP names (\texttt{first.row = FALSE})
or the data for the first subject (\texttt{first.row = TRUE}). In the former case, \texttt{read.pedfile()} adds the SNP names
(with extensions \texttt{.1} and \texttt{.2} to differ between the two alleles) to the respective columns of the read-in data frame. 

For the applications of the functions for performing gTDTs (see Section \ref{testing}), 
the trio data must be in a matrix in genotype format. In such a matrix,
each columns represents a SNP, which is coded by the number of minor alleles, and each block of 3 consecutive rows contains the genotypes
of the father, the mother, and their offspring (in this order) of one specific trio. Missing values are allowed in this matrix, and
need to be coded by \texttt{NA}. This matrix can either be generated from a data frame in ped format by employing the function
\texttt{ped2geno()}, or more conveniently, by setting \texttt{p2g = TRUE} in \texttt{read.pedfile()}. Thus, a matrix in genotype format
might be obtained from the above ped file by calling

\begin{verbatim}
   > geno <- read.pedfile("pedfile.ped", p2g=TRUE)
\end{verbatim}
The output of these functions just contains the matrix in genotype format, whereas \texttt{trio.check()} described in
Section \ref{trio} additionally contains information
about Mendelian errors. Instead of checking for Mendelian errors in \texttt{ped2geno()} or \texttt{read.pedfile()}, 
such errors are removed SNP-wise in the functions for performing genotypic TDTs.

If, for example, the data frame \texttt{trio.ped1} should be transformed into a
matrix in genotype format, \texttt{ped2geno()} can be applied to it. However, \texttt{ped2geno()} requires unique personal IDs
(second column of \texttt{trio.ped1}) such that we first have to combine the family ID and the personal ID (which would be automatically
done by \texttt{read.pedfile()}), and change the IDs of the fathers and mothers in columns 3 and 4 likewise.

<<>>=
data(trio.data)
trio.ped1[,2] <- paste(trio.ped1[,1], trio.ped1[,2], sep="_")
ids <- trio.ped1[,3] != 0
trio.ped1[ids,3] <- paste(trio.ped1[ids,1], trio.ped1[ids,3], sep="_")
trio.ped1[ids,4] <- paste(trio.ped1[ids,1], trio.ped1[ids,4], sep="_")
trio.ped1[1:5, 1:4]
@

Afterwards, \texttt{ped2geno()} can be applied to \texttt{trio.ped1}

<<>>=
geno <- ped2geno(trio.ped1)
geno[1:5,]
@

The matrix \texttt{trio.gen1} is the genotype matrix corresponding to
\texttt{trio.ped1}. So the genotypes in the output of \texttt{ped2geno()} are identical to
\texttt{trio.gen1} (except for that the first two columns of \texttt{trio.gen1} contain the family ID and the personal ID). 

<<>>=
data(trio.data)
trio.gen1[1:5, 3:12]
table(trio.gen1[,3:12] == geno)
@

\section{Testing SNPs, pairs of SNPs, and GxE interactions}\label{testing}

A single SNP or two-way interaction can be tested with a gTDT by employing the functions \texttt{tdt()}
and \texttt{tdt2way()}. If we, for example, would like to test the first SNP in the matrix \texttt{mat.test}
available in the \texttt{R} package \texttt{trio}, then this could be done by calling

<<>>=
data(trio.data)
tdt(mat.test[,1])
@

In this case, a conditional logistic regression is fitted, and the output of \texttt{tdt()} contains the
parameter estimate \texttt{Coef} for the SNP in this model, the odds ratio \texttt{OR}, the \texttt{Lower}
and \texttt{Upper} bound of the 95\% confidence interval of this odds ratio, the standard error \texttt{SE}
of the parameter estimate, the Wald \texttt{Statistic} for testing whether this SNP has an effect, and
the corresponding \texttt{p-Value}.

By default, an additive effect is tested. It is, however, also possible to consider a dominant effect
<<>>=
tdt(mat.test[,1], model="dominant")
@

or a recessive effect
<<>>=
tdt(mat.test[,1], model="recessive")
@

Similarly the interaction between \texttt{SNP1} and \texttt{SNP2} in \texttt{mat.test} can be tested by

<<>>=
tdt2way(mat.test[,1], mat.test[,2])
@

In this case, the interaction is tested for epistatic interactions as described in \citet{cordell2002}.
Thus, two conditional logistic regression models are fitted to the cases and the respective 15 matched pseudo-controls
(i.e.\ the 15 possible, but not transmitted Mendelian genotype realizations, given the parents' genotypes at the two loci), 
one consisting of two dummy variables for each
of the two SNPs, and the other additionally containing the four possible interactions of these dummy variables.
The two fitted models are then compared by a likelihood ratio test, and the $p$-values are computed by approximation
to a $\chi^2$-distribution with four degrees of freedom.

This is the recommended way to test the two-way interaction. \texttt{tdt2way()}, however,
also provides a simpler test, in which the values of the SNPs (either coding for an additive -- which is the default --
for a recessive, or for a dominant model) are simply multiplied for each case and its 15 matched pseudo-controls, 
and a conditional logistic regression is applied to this interaction.

<<>>=
tdt2way(mat.test[,1], mat.test[,2], epistatic=FALSE)
@

All SNPs represented by the columns of a matrix in genotype format can be tested with a gTDT by employing the function \texttt{colTDT()}.
Thus, all SNPs in \texttt{mat.test} can be tested by calling

<<>>=
tdt.out <- colTDT(mat.test)
tdt.out
@

By default, the five top SNPs, i.e.\ the five SNPs with the lowest $p$-values, are shown ordered by their significance. 
The top three SNPs can be shown by

<<>>=
print(tdt.out, 3)
@

If the integer specified in \texttt{print()} is larger than or equal to the number of SNPs in the input matrix, the
statistics for all SNPs are displayed in the order of their appearance in this matrix.

<<>>=
print(tdt.out, 10)
@

Since the genetic mode of inheritance is typically unknown, it might be beneficial to use the maximum over the gTDT statistics
for an additive, a dominant, and a recessive effect as test statistic, which can be done using the function \texttt{colTDTmaxStat()}

<<>>=
max.stat <- colTDTmaxStat(mat.test)
max.stat
@

This function just computes the MAX gTDT statistic, i.e.\ the maximum over the three gTDT statistics, since in contrast to these
gTDT statistics, which under the null hypothesis follow an asymptotic $\chi^2_1$-distribution, the null distribution of the MAX gTDT
statistic is unknown, and must therefore be estimated by a (time-consuming) permutation procedure. To also determine permutation-based
p-values, \texttt{colTDTmaxTest()} can be applied to a matrix in genotype matrix. For example,

<<>>=
max.out <- colTDTmaxTest(mat.test, perm=1000)
@

computes p-values for the six SNPs in \texttt{mat.test} based on 1000 permutations of the case-pseudo-control status.

<<>>=
max.out
@

All two-way interactions comprised a matrix in genotype format can be tested using the function \texttt{colTDT2way()}. Since both the gTDT
for two-way interactions and the likelihood ratio test of \citet{cordell2004}
assume that the two considered loci are unlinked, the testing might fail, i.e.\ the fitting of the 
conditional logistic regression might not work pro\-per\-ly, if the two SNPs are in (strong) LD. (Another reason why the fitting
might not work properly is that the minor allele frequencies of both SNPs are very small.) Therefore, \texttt{colTDT2way()}
provides an argument called \texttt{genes} that allows specifying which SNP belongs to which LD-block, gene, or genetic region.
If \texttt{genes} is not specified, the interactions between all $m(m-1)/2$ pairs of the $m$ SNPs in a matrix are tested.
If specified, only the interactions between SNPs showing different values of \texttt{genes} are tested.

If we thus assume that the first two SNPs in \texttt{mat.test} belong to gene \texttt{G1} and the other four SNPs to
\texttt{G2}

<<>>=
genes <- paste("G", rep(1:2, c(2,4)), sep="")
genes
@

then only the four interactions between \texttt{SNP1} and each SNP from gene \texttt{G2}, as well as the four interactions
between \texttt{SNP2} and each SNP from gene \texttt{G2} are tested, when calling

<<>>=
tdt2.out <- colTDT2way(mat.test, genes=genes)
tdt2.out
@

Again, by default the top five SNP interactions are shown. The statistics for all eight interactions can be displayed by calling
<<>>=
print(tdt2.out, 8)
@ 

In genetic association studies, it is often also of interest to test gene-environment interactions, where most of the usually
considered environmental variables are binary. The \texttt{R} package \texttt{trio} therefore also provides a function called
\texttt{colGxE} to test the interactions between each of the SNPs comprised by a matrix in genotype format and a binary environmental
variable with values zero and one. If we, for example, assume that the children in the first 50 trios comprised by (the first 150 rows of)
\texttt{mat.test} are girls, and the remaining 50 are boys,

<<>>=
sex <- rep(0:1, e=50)
@

then we can test the interactions between the six SNPs in \texttt{mat.test} and the environmental variable ``sex" by

<<>>=
gxe.out <- colGxE(mat.test, sex)
gxe.out
@

In this situation, a conditional logistic regression model $\beta_1 G + \beta_2 (G\times E)$ is fitted for each SNP, where $G$ is
a variable coding for an additive effect of the SNP, and $G\times E$ is the corresponding gene-environment interaction. Analogously
to the other gTDT functions, a dominant or a recessive effect can also be considered by changing the argument \texttt{model} of
\texttt{colGxE}. The output
contains the same statistics as, for example, \texttt{colTDT} for both $\beta_1$ and $\beta_2$, where the statistics for $\beta_2$
are printed first, as these are here the effects of interest. The printing of the statistics for the testing of $G$ can be avoided
by calling

<<>>=
print(gxe.out, onlyGxE=TRUE)
@


\section{Generating data for trio logic regression input}\label{trio}

If interactions of a higher order than two are of interest, trio logic regression
can be used to detect disease-associated SNP interactions of any order.

To generate data that can be used as input in trio logic regression,
the sequential application of two functions is required. The function
\texttt{trio.check()} evaluates whether or not Mendelian errors are
present in the data (stored either in linkage or in genotype format,
see Section \ref{supported}). If no Mendelian inconsistencies are detected, this
function creates an object that is passed to the function
\texttt{trio()}. The latter function then generates a matrix of the
genotype information for the affected probands and the inferred
pseudo-controls, taking the observed LD structure into
account. Missing data are imputed in the process. The user, however,
has to supply the information for the lengths of the LD blocks. 
A function called \texttt{findLDblocks()} for identifying LD blocks, and thus, for
specifying the length of the blocks is therefore also contained in this package (see Section \ref{getLD}).
Given the lengths of the LD blocks, the haplotype frequencies can be
estimated, using the function \texttt{haplo.em()} in the
\texttt{haplo.stat} package.


\subsection{Supported file formats and elementary data processing}\label{supported}

In this section, we show how to generate data suitable for input to
trio logic regression from complete pedigree data without Mendelian
errors. The function \texttt{trio.check()} requires that the trio data are
already available as a data frame or matrix, either in linkage/ped format
(the default), or in genotype format (for reading a ped file into \texttt{R}, see Section \ref{testing}).


The first function used is always \texttt{trio.check()}. Unless
otherwise specified, this function assumes that the data are in
linkage format. If no Mendelian inconsistencies in the data provided
are identified, \texttt{trio.check()} creates an object that can be
processed in the subsequent analysis with this package. The genotype
information for each SNP will be converted into a single variable,
denoting the number of variant alleles.

If we thus would like to check whether the data frame \texttt{trio.ped1} contains Mendelian errors, we call

%chunk2
<<>>=
data(trio.data)
trio.tmp <- trio.check(dat=trio.ped1)
str(trio.tmp, max=1)
trio.tmp$trio[1:6,]
@ 

Taking the LD structure of the SNPs into account is imperative when creating
the genotypes for the pseudo-controls. This requires information on
the LD blocks. However, there are many ways to delineate this block
structure, and in the absence of a consensus what the best approach
is, researchers have different preferences, and thus, results can be
different. %It is therefore assumed that the user has already
%delineated the block structure according to his or her method of
%choice (assumed to be 1, 4, 2, and 3 in the following examples).
In the function \texttt{findLDblocks()}, a modified version of the method of \cite{gabriel2002}
has been implemented, which can be used to specify the block structure by
\begin{verbatim}
   > table(foundBlocks$blocks}
\end{verbatim}
if \texttt{foundBlocks} is the output of \texttt{findLDblocks()} (for details, see Section \ref{getLD}).

The function \texttt{trio()}, which operates on an output
object of \text{trio.check()}, accepts the block length information as
an argument (in the following, we assume that the block structure is given by \texttt{c(1, 4, 2, 3)},
i.e.\ the first block consists only of the first SNP, the second block of the next four SNPs, the third
of the following two SNPs, and the last block of the remaining three SNPs). 
If this argument is not specified, a uniform block length
of 1 (i.e.\ no LD structure) is assumed. If the haplotype frequencies
are not specified, they are estimated from the parents' genotypes
(more information on this in the following sections).  The function
\texttt{trio()} then returns a list that contains the genotype
information in binary format, suitable as input for trio logic
regression: \texttt{bin} is a matrix with the conditional logistic
regression response in the first columns, and each SNP as two binary
variables using dominant and recessive coding. The list element \texttt{miss} contains
information about missing values in the original data, and
\texttt{freq} contains information on the estimated haplotype
frequencies.

%chunk3
<<>>=
trio.bin <- trio(trio.dat=trio.tmp, blocks=c(1,4,2,3))
str(trio.bin, max=1)

trio.bin$bin[1:8,]
@ 

As mentioned above, the \texttt{trio} package also accommodates trio
genotype data.  The object \texttt{trio.gen1}, available in the \texttt{R}
package, is an example of such a data set. Equivalent to
\texttt{trio.ped1} used above, it contains information for 10 SNPs in
100 trios. When used in \texttt{trio.check()}, the argument
\texttt{is.linkage} needs to be set to \texttt{FALSE}. The output from this
function is then identical to the one shown derived from the linkage
file, and can be passed to the function \texttt{trio()}.

%chunk4
<<>>=
data(trio.data)
str(trio.gen1)
trio.gen1[1:10,1:12]
trio.tmp <- trio.check(dat=trio.gen1, is.linkage=F)
trio.bin <- trio(trio.dat=trio.tmp, blocks=c(1,4,2,3))
@ 


\subsection{Missing genotype information}\label{missing}

Missing genotypes in ped(igree) files are typically encoded using the
integer 0. The data files can be processed as before if they contain
such missing values:
%chunk5
<<>>=
data(trio.data)
str(trio.ped2)

trio.tmp <- trio.check(dat=trio.ped2)
trio.tmp$trio[1:6,]
@ 

Since trio logic regression requires complete data, the function
\texttt{trio()} also performs an imputation of the missing
genotypes. The imputation is based on estimated haplotypes, using the
block length information specified by the user. In a later section we
demonstrate how this imputation can be run more efficiently when
haplotype frequency estimates are already available.

%chunk6
<<>>=
trio.bin <- trio(trio.dat=trio.tmp, blocks=c(1,4,2,3))
trio.bin$bin[1:8,]
@ 

Missing data in genotypes files should be encoded using \texttt{NA},
the conventional symbol in \texttt{R} to indicate missing values.

%chunk7
<<>>=
data(trio.data)
str(trio.gen2)
trio.tmp <- trio.check(dat=trio.gen2, is.linkage=FALSE)
trio.bin <- trio(trio.dat=trio.tmp, blocks=c(1,4,2,3))
trio.bin$bin[1:8,]
@

As the user might also be interested in the completed genotype data in
the original format (genotype or linkage file), the function
\texttt{trio()} also allows for this option by using the argument
\texttt{logic = FALSE}. In the resulting object, the matrix \texttt{bin} is
then replaced by the data frame \texttt{trio}, and \texttt{miss} and
\texttt{freq} are also returned.

%chunk8
<<>>=
data(trio.data)
trio.tmp <- trio.check(dat=trio.gen2, is.linkage=FALSE)
trio.imp <- trio(trio.dat=trio.tmp, blocks=c(1,4,2,3), logic=FALSE)
str(trio.imp, max=1)
trio.imp$miss[c(1:6),]
print(trio.gen2[1:6,])
print(trio.imp$trio[1:6,])
@ 

The same applies to pedigree data:
%chunk9
<<>>=
data(trio.data)
trio.tmp <- trio.check(dat=trio.ped2)
trio.imp <- trio(trio.dat=trio.tmp, blocks=c(1,4,2,3), logic=FALSE)
@ 


\subsection{Mendelian errors}\label{mendelian}

To delineate the genotype information for the pseudo-controls, the
trio data must not contain any Mendelian errors. The function
\texttt{trio.check()} returns a warning, and an \texttt{R} object with relevant
information when Mendelian errors are encountered is created. 

%chunk10
<<>>=
data(trio.data)
trio.tmp <- trio.check(dat=trio.ped.err)
str(trio.tmp, max=1)
trio.tmp$errors
@ 

In this data set, trio 1, for example, contains two Mendelian errors, in SNPs 9 and 10.

%chunk11
<<>>=
trio.tmp$trio.err[1:3, c(1,2, 11:12)]
trio.ped.err[1:3,c(1:2, 23:26)]
@ 

It is the user's responsibility to find the cause for the Mendelian
errors and correct those, if possible. However, Mendelian
inconsistencies are often due to genotyping errors and thus, it might
not be possible to correct those in a very straight-forward manner. In
this instance, the user might want to encode the genotypes that cause
theses Mendelian errors in some of the trios as missing data. The
argument \texttt{replace = TRUE} in \texttt{trio.check()} allows for this
possibility. The resulting missing data can then be imputed as
described in the previous section.

%chunk12
<<>>=
trio.rep <- trio.check(dat=trio.ped.err, replace=TRUE)
str(trio.rep, max=1)
trio.rep$trio[1:3,11:12]
@ 

The same option is available for data in genotype format with
Mendelian inconsistencies.

%chunk13
<<>>=
data(trio.data)
trio.tmp <- trio.check(dat=trio.gen.err, is.linkage=FALSE)
trio.tmp$errors
trio.tmp$trio.err[1:6, c(1,2,7), drop=F]
trio.rep <- trio.check(dat=trio.gen.err, is.linkage=FALSE, replace=TRUE)
trio.rep$trio[1:6,c(1,2,7)]
@ 

\subsection{Using haplotype frequencies}

As mentioned above, when estimates for the haplotype frequencies are
already available, they can be used in the
imputation of missing data and the delineation of the
pseudo-controls. In case there are blocks of length one, i.e.\ SNPs
not belonging to any LD blocks, the minor allele frequencies of those
SNPs are supplied. In this case, no haplotype estimation
is required when the function \texttt{trio()} is run, which can result
in substantial time savings. 

As an example for the format of a file containing haplotype frequency
estimates and SNP minor allele frequencies, the object
\texttt{freq.hap} is available in the \texttt{R} package:

<<>>=
data(trio.data)
str(freq.hap)
freq.hap[1:6,]
@ 

We can now impute the missing genotypes using these underlying haplotype frequencies.
<<>>=
data(trio.data)
trio.tmp <- trio.check(dat=trio.gen2, is.linkage=FALSE)
trio.imp <- trio(trio.dat=trio.tmp, freq=freq.hap, logic=FALSE)
str(trio.imp, max=1)
print(trio.gen2[1:6,])
print(trio.imp$trio[1:6,])
@

\subsection{Trio Logic Regression}

Trio logic regression can be applied to case-parent trio data using the standard \texttt{R} function \texttt{logreg}
(available in the \texttt{R} package \texttt{LogicReg}) to perform a logic regression by employing a plug-in 
provided by the \texttt{R} package \texttt{trio}. However,
this requires to modify and recompile \texttt{LogicReg}, which can be done in the following way:
\begin{enumerate}
\item Download the package source for \texttt{LogicReg} from 
\url{http://cran.r-project.org/web/packages/LogicReg/index.html}.
\item Extract this package.
\item Replace the file \texttt{My\_own\_scoring.f} available in the subdirectory \texttt{src} of \texttt{LogicReg}
by the file \texttt{My\_own\_scoring.f} provided in the subdirectory \texttt{plugin} of the \texttt{R} package \texttt{trio}.
\item Recompile the modified \texttt{LogicReg} by applying \texttt{R CMD build} to it (for details on how
to check and build \texttt{R} packages, see
\url{http://cran.r-project.org/doc/manuals/R-exts.html}).
\item Install this recompiled package.
\end{enumerate}

After installing and loading this recompiled package, trio logic regression can be applied to \texttt{trio.bin} or to \texttt{trio.imp}
(see Sections \ref{missing} and \ref{mendelian}) by
\begin{verbatim}
   > library(LogicReg)
   > resp <- trio.bin$bin[,1]
   > bin <- trio.bin$bin[,-1]
   > triolr.out <- logreg(resp=resp, bin=bin, type=0, ntrees=1, ...)
\end{verbatim}
where the $\ldots$ should indicate that all other arguments of \texttt{logreg}
such as \texttt{select} (type of model selection) and \texttt{nleaves} (the maximum
number of leaves that the logic tree in the trio logic regression model is allowed to have) need to be or can be specified
as in a typical logic regression analysis. One restriction is that in trio logic regression currently just one logic tree
can be grown, and therefore, \texttt{ntrees} needs to be set to \texttt{1}. 

Adding the trio logic regression plug-in to \texttt{LogicReg} allows making use of almost all the features implemented
in \texttt{logreg}. The only exceptions are the two permutation tests provided by \texttt{logreg}. The standard implementation
for performing these null-model and conditional permutation tests cannot be applied to case-parent trio data, as the
special structure of these data must be taken into account by the permutation method. Therefore, the \texttt{R} package
\texttt{trio} provides a function called \texttt{trio.permTest} that can be used to apply null-model test with, for example, 20 permutations 
to the case-parent trio data in \texttt{trio.bin} by calling
\begin{verbatim}
   > trio.permTest(triolr.out, n.perm=20)
\end{verbatim}
and the conditional permutation test can be performed by
\begin{verbatim}
   > trio.permTest(triolr.out, conditional=TRUE, n.perm=20)
\end{verbatim}


\section{Detection of LD blocks}\label{getLD}

For the estimation of the haplotype structure that might be used in the \texttt{R} function \texttt{trio()},
this package also includes functions for the fast computation of the pairwise $D^\prime$ and $r^2$
values for hundreds or thousands of SNPs, and for the identification of LD blocks in these genotype
data using a modified version of the algorithm proposed by \citet{gabriel2002}. For the latter, it
is assumed that the SNPs are ordered by their position on the chromosomes.

These functions are not restricted to trio data, but can also be applied to population-based data.
The only argument of these functions specifically included for trio data is \texttt{parentsOnly}.
If set to \texttt{TRUE}, only the genotypes of the parents are used in the determination of
the pairwise values of the LD measures and the estimation of the LD blocks. Furthermore, each parent
is only considered once so that parents with more than one offspring do not bias the estimations.
If trio data is used as input, the functions assume that the matrix containing the SNP data is in genotype format.

Here, we consider a simulated matrix \texttt{LDdata} from a population-based study. Thus, all subjects are assumed
to be unrelated. This matrix contains simulated genotype data for 10 LD blocks each consisting of 5 SNPs each typed
on 500 subjects. The pairwise $D^\prime$ and $r^2$ values for the SNPs in this matrix can be computed by

<<>>=
data(trio.data)
ld.out <- getLD(LDdata, asMatrix=TRUE)
@ 

where by the default these values are stored in vectors to save memory. If \texttt{asMatrix} is set to \texttt{TRUE},
the values will be stored in matrices. The pairwise LD values for the first 10 SNPs (rounded to the second digit) can be displayed
by

<<>>=
round(ld.out$Dprime[1:10,1:10], 2)
@

<<>>=
round(ld.out$rSquare[1:10,1:10], 2)
@

and the pairwise LD plot for all SNPs can be generated by

\begin{figure}[!t]
\centerline{\includegraphics[width=0.5\textwidth]{figure1}}
\caption{Pairwise $r^2$ values for the SNPs from \texttt{LDdata}.}\label{fig:1}
\end{figure} 

\begin{verbatim}
   > plot(ld.out)
\end{verbatim}
(see Figure \ref{fig:1}). This figure shows the $r^2$-values. The $D^\prime$ values can be plotted by

\begin{verbatim}
   > plot(ld.out, "Dprime")
\end{verbatim} 
(not shown).


\begin{figure}[!t]
\centerline{\includegraphics[width=0.5\textwidth]{figure2}}
\caption{LD blocks as found by the modified algorithm of \citet{gabriel2002}. The borders of the LD blocks are marked
by red lines. The color for the LD between each pair of SNPs is defined by the three categories used by \citet{gabriel2002} 
to define the LD blocks.}\label{fig:2}
\end{figure} 

The LD blocks in genotype data can be identified using the modified algorithm of \citet{gabriel2002}
by calling

<<>>=
blocks <- findLDblocks(LDdata)
blocks
@

Alternatively, the output of \texttt{getLD()} can be used when \texttt{addVarN} has been set to \texttt{TRUE}
in \texttt{getLD()} to store additional information on the pairwise LD values.

<<>>=
ld.out2 <- getLD(LDdata, addVarN=TRUE)
blocks2 <- findLDblocks(ld.out2)
blocks2
@

The blocks can also be plotted by

\begin{verbatim}
   > plot(blocks)
\end{verbatim}
(see Figure \ref{fig:2}). In this figure, the borders of the LD blocks are marked by red lines.
By default, the three categories used by the algorithm of \citet{gabriel2002} to define the LD blocks are
displayed. Since this algorithm is based on the $D^\prime$ values, it is also possible to show these values in
the LD (block) plot.


\begin{figure}[!t]
\centerline{\includegraphics[width=0.5\textwidth]{figure3}}
\vspace*{-8pt}
\caption{LD blocks as found by the modified algorithm of \citet{gabriel2002}. The borders of the LD blocks are marked
by red lines. The darker the field for each pair of SNPs, the larger is the $D^\prime$ value for the corresponding SNP pair.}\label{fig:3}
\end{figure} 

\begin{verbatim}
   > plot(blocks, "Dprime")
\end{verbatim}
(see Figure \ref{fig:3}). 

As mentioned in Section \ref{trio}, the haplotype structure required by \texttt{trio()} can be obtained by

<<>>=
hap <- as.vector(table(blocks$blocks))
hap
@



\section{Simulation}\label{simulation}


The function \texttt{trio.sim()} simulates case-parents trio data when
the disease risk of children is specified by (possibly higher-order)
SNP interactions. The mating tables and the respective sampling
probabilities depend on the haplotype frequencies (or SNP minor allele
frequencies when the SNP does not belong to a block). This information
is specified in the \texttt{freq} argument of the function
\texttt{trio.sim()}. The probability of disease is assumed to be
described by the logistic term $\text{logit}(p) = \alpha + \beta
\times \text{Interaction}$, where $\alpha = \text{logit (\texttt{prev})}=\log(
\frac{\text{\texttt{prev}}}{1-\text{\texttt{prev}}} )$ and $\beta =
\log(\text{\texttt{OR}})$. The arguments \texttt{interaction, prev} and
\texttt{OR}, are specified in the function \texttt{trio.sim()}. Generating the mating tables and the
respective sampling probabilities, in particular for higher order
interactions, can be very CPU and memory intensive. We show how this
information, once it has been generated, can be used for future
simulations, and thus, speed up the simulations dramatically.


\subsection{A basic example}

We use the built-in object \texttt{simuBkMap} in a basic example to
show how to simulate case-parent trios when the disease risk depends
on (possibly higher order) SNP interactions. This file contains
haplotype frequency information on 15 blocks with a total of 45 loci.
In this example, we specify that the children with two variant alleles
on SNP1 and two variant alleles on SNP5 have a higher disease risk. We
assume that \texttt{prev = 0.001} and \texttt{OR = 2} in the logistic model specifying
disease risk, and simulate a single replicate of 20 trios total. 


<<>>=
data(trio.data)
str(simuBkMap)
simuBkMap[1:7,]
sim <- trio.sim(freq=simuBkMap, interaction="1R and 5R", prev=.001, OR=2, 
n=20, rep=1)
str(sim)
sim[[1]][1:6, 1:12]
@  



\subsection{Using estimated haplotype frequencies}

In this example we estimate the haplotype frequencies in the built-in
data set \texttt{trio.gen1}, which contains genotypes for 10 SNPs
in 100 trios. These estimated frequencies are then used to simulate 20
trios for the above specified disease risk model.

<<>>=
data(trio.data)
trio.tmp <- trio.check(dat=trio.gen1, is.linkage=FALSE)
trio.impu <- trio(trio.dat=trio.tmp, blocks=c(1,4,2,3), logic=TRUE)

str(trio.impu, max=2)
trio.impu$freq[1:7,]
sim <- trio.sim(freq=trio.impu$freq, interaction="1R and 5R", prev=.001, OR=2, 
n=20, rep=1)

str(sim)
sim[[1]][1:6, ]
@

As before, the object containing the haplotype frequency information
can also be generated from external haplotype frequencies and SNP
minor allele frequencies. In
the following example we specify the haplotype frequencies, and generate two replicates of ten
trios each.

<<>>=
data(trio.data)

sim <- trio.sim(freq=freq.hap, interaction="1R or 4D", prev=.001, OR=2, 
n=10, rep=2)
str(sim)
sim[[1]][1:6,]
@ 


\subsection{Using step-stones}

Generating the mating tables and the respective sampling probabilities
necessary to simulate case-parent trios can be very time consuming for
interaction models involving three or more SNPs. In simulation
studies, many replicates of similar data are usually required, and
generating these sampling probabilities in each instance would be a
large and avoidable computational burden (CPU and memory). The
sampling probabilities depend foremost on the interaction term and the
underlying haplotype frequencies, and as long as these remain constant
in the simulation study, the mating table information and the sampling
probabilities can be ``recycled.'' This is done by storing the
relevant information (denoted as ``step-stone'') as a binary \texttt{R} file in
the working directory, and loading the binary file again in future
simulations, speeding up the simulation process dramatically. It is
even possible to change the parameters \texttt{prev} and \texttt{OR} in these
additional simulations, as the sampling probabilities can be adjusted
accordingly.

In the following example, we first simulate case-parent trios using a
three-SNP interaction risk model, and save the step-stone object. We
then simulate additional trios with a different parameter \texttt{OR},
using the previously generated information.

<<>>=
data(trio.data)

sim <- trio.sim(freq=freq.hap, interaction="1R or (6R and 10D)", prev=.001, 
OR=2, n=10, rep=1)
str(sim)
sim[[1]][1:6,]
@ 

<<>>=
sim <- trio.sim(freq=freq.hap, interaction="1R or (6R and 10D)", prev=.001, 
OR=3, n=10, rep=1, step.save="step3way")
str(sim, max=1)
sim[[1]][1:6,]
@ 




\section*{Acknowledgments}
Support was provided by NIH grants R01 DK061662 and R01 HL090577, and by DFG grant SCHW 1508/1-1 and SCHW 1508/2-1.

%\clearpage
%\bibliography{xbib_appFinal}
%\bibliographystyle{mypapers}

\begin{thebibliography}{4}

\bibitem[Cordell(2002)Cordell]{cordell2002}
Cordell, H.J. (2002).
\newblock Epistasis: What it means, what it doesn't mean, and statistical
  methods to detect it in humans.
\newblock {\em Hum. Mol. Genet.}, {\bf 11}, 2463--2468.

\bibitem[Cordell {\em et al.}(2004)Cordell, Barratt, and Clayton]{cordell2004}
Cordell, H.J., Barratt, B.J., and Clayton, D.G. (2004).
\newblock Case/pseudocontrol analysis in genetic association studies: A unified
  framework for detection of genotype and haplotype associations, gene-gene and
  gene-environment interactions, and parent-of-origin effects.
\newblock {\em Genet. Epidemiol.}, {\bf 26}, 167--185.

\bibitem[Gabriel {\em et al.}(2002)Gabriel, Schaffner, Nguyen, Moore, Roy,
  Blumenstiel, Higgins, {DeFelice}, Lochner, Faggart, {Liu-Cordero}, Rotimi,
  Adeyemo, Cooper, Ward, Lander, Daly, and Altshuler]{gabriel2002}
Gabriel, S.B., Schaffner, S.F., Nguyen, H., Moore, J.M., Roy, J.,
  Blumenstiel, B., Higgins, J., {DeFelice}, M., Lochner, A., Faggart, M.,
  {Liu-Cordero}, S.N., Rotimi, C., Adeyemo, A., Cooper, R., Ward, R., Lander,
  E.S., Daly, M.J., and Altshuler, D. (2002).
\newblock The structure of haplotype blocks in the human genome.
\newblock {\em Science\/}, {\bf 296}, 2225--2229.

\bibitem[Li {\em et al.}(2010)Li, Fallin, Louis, Lasseter, {McGrath},
  Avramopoulos, Wolyniec, Valle, Liang, Pulver, and Ruczinski]{li2010}
Li, Q., Fallin, M.D., Louis, T.A., Lasseter, V.K., {McGrath}, J.A.,
  Avramopoulos, D., Wolyniec, P.S., Valle, D., Liang, K.Y., Pulver, A.E.,
  and Ruczinski, I. (2010).
\newblock Detection of {SNP-SNP} interactions in trios of parents with
  schizophrenic children.
\newblock {\em Genet. Epidemiol.}, {\bf 34}, 396--406.

\bibitem[Schaid(1996)Schaid]{schaid1996}
Schaid, D.J. (1996).
\newblock General score tests for associations of genetic markers with disease
  using cases and their parents.
\newblock {\em Genet. Epidemiol.}, {\bf 13}, 423--449.

\end{thebibliography}

\end{document}
