\documentclass[12pt]{article}
\SweaveOpts{keep.source=TRUE, expand=FALSE}
%\VignetteIndexEntry{Trio Package for Trio Logic Regression}
%\VignetteDepends{trio}
%\VignettePackage{trio} 

\usepackage[margin=1.25in]{geometry}

\usepackage{color,colordvi}

\usepackage{amsmath,amstext}
%\usepackage{psfig}
\usepackage{natbib}
\usepackage{graphicx}
%\usepackage[tight]{subfigure}
%\usepackage{lscape,rotating,setspace,tabularx}

\usepackage{fancyhdr}
\usepackage{fancyvrb}
\usepackage{setspace}
\usepackage{verbatim}
\usepackage{qingSweave}

\newcommand{\captionfonts}{\small}


%\setlength{\topmargin}{-15mm}
\setlength{\parskip}{2ex plus0.5ex minus0.2ex}

\doublespacing
\parindent0em


\renewcommand{\familydefault}{cmss}

\begin{document}

\thispagestyle{empty}

\bigskip

\begin{center}

{\LARGE \bf A Vignette for the R Package \texttt{trio}}

\end{center}

\newpage
\doublespace


\section{Introduction}

The R package, \texttt{trio}, provides functionality relevant
for the analysis of case-parent trio data with {\it trio logic
  regression}. Two major features are implemented in this package:
functions that aid in the transformation of the trio data from
standard linkage files (ped format) or genotype format into objects
suitable as input for trio logic regression, and a framework that
allows for the simulation of case-parent data where the risk of
disease is specified by (higher order) SNP-SNP interactions. 

The first section of this vignette is devoted to the steps relevant
for data processing, to derive a matrix or data frame suitable as
input for trio logic regression, starting from a linkage or genotype
file which possibly contains missing data and/or Mendelian errors. We
give some examples how missing data can be addressed using haplotype
based imputation. The haplotype information can be specified by the
user, or when this information is not readily available, automatically
inferred. The haplotype blocks are also relevant in the delineation of
the genotypes for the pseudo-controls, as the linkage disequilibrium
(LD) structure observed in the parents is taken into account in this
process. While this function is intended to generate complete case
pseudo-control data as input for trio logic regression, an option to
simply return the completed trio data is available.

The second section of the vignette explains in more detail how to set
up simulations of case-parent data where the risk of disease is
specified by SNP-SNP interactions. The most time consuming step for
these types of simulations is the generation of mating tables and
the respective probabilities. The mating table information however can
be stored, which allows for fast simulations when replicates of the
case-parent data are generated.



\section{Generating data for trio logic regression input}\label{trio}

To generate data that can be used as input in trio logic regression,
the sequential application of two functions is required. The function
\texttt{trio.check} evaluates whether or not Mendelian errors are
present in the data (stored in either in linkage or genotype format,
see below). If no Mendelian inconsistencies are detected, this
function creates an object that is passed to the function
\texttt{trio}. The latter function then generates a matrix of the
genotype information for the affected probands and the inferred
pseudo-controls, taking the observed LD structure into
account. Missing data are imputed in the process. The user, however,
has to supply the information for the lengths of the LD blocks. 
%As of
%April 2009, it appears that there is no R package that delineates
%haplotype block segments from genotype data. Thus, external programs
%such as HaploView (\cite{RefWorks:1434}) or HapBlock
%(\cite{RefWorks:1437,RefWorks:1436}) need to be employed for this purpose. 
A function called \texttt{findLDblocks} for identifying LD blocks, and thus, for
specifying the length of the blocks is therefore also contained in this package (see Section \ref{getLD}).
Given the LD block lengths, the haplotype frequencies can be
estimated, using the function \texttt{haplo.em()} in the
\texttt{haplo.stat} package.


\subsection*{Supported file formats and elementary data processing}

In this section, we show how to generate data suitable for input to
trio logic regression from complete pedigree data without Mendelian
errors.  The \texttt{trio} package requires that the trio data are
already available as an R object, either as linkage file in ped format
(the default), or as genotype file.  The first six columns in such a
linkage file identify the family structure of the data, and the
phenotype. It is assumed that only one phenotype variable (column 6)
is used.  The object \texttt{trio.ped1}, available in the R package,
is an example of such a data set. It contains information for 10 SNPs
in 100 trios. Besides the variables providing information on the
family structure and the phenotypes (columns 1--6), each SNPs is
encoded in two variables denoting the alleles.

%chunk1
<<>>=
library(trio)
data(trio.ped1)
str(trio.ped1)
trio.ped1[1:10,1:12]
@


The first function used is always \texttt{trio.check()}. Unless
otherwise specified, this function assumes that the data are in
linkage format. If no Mendelian inconsistencies in the data provided
are identified, \texttt{trio.check()} creates an object that can be
processed in the subsequent analysis with this package. The genotype
information for each SNP will be converted into a single variable,
denoting the number of variant alleles.

%chunk2
<<>>=
trio.tmp = trio.check(dat=trio.ped1)
str(trio.tmp, max=1)
trio.tmp$trio[1:6,]
@ 

Taking the SNP LD structure into account is imperative when creating
the genotypes for the pseudo-controls. This requires information on
the LD ``blocks.'' However, there are many ways to delineate this block
structure, and in the absence of a consensus what the best approach
is, researchers have different preferences, and thus, results can be
different. %It is therefore assumed that the user has already
%delineated the block structure according to his or her method of
%choice (assumed to be 1, 4, 2, and 3 in the following examples).
In the function \texttt{findLDblocks}, a modified version of the method of \cite{gabriel2002}
has been implemented, which can be used to specify the block structure by
\begin{verbatim}
> table(foundBlocks$blocks}
\end{verbatim}
if \texttt{foundBlocks} is the output of \texttt{findLDblocks} (for details, see Section \ref{getLD}).

The function \texttt{trio()}, which operates on an output
object of \text{trio.check()}, accepts the block length information as
an argument (in the following, we assume that the block structure is given by \texttt{c(1, 4, 2, 3)},
i.e.\ the first block consists only of the first SNP, the second block of the next four SNPs, the third
of the following two SNPs, and the last block of the remaining three SNPs). 
If this argument is not specified, a uniform block length
of 1 (i.e.~no LD structure) is assumed. If the haplotype frequencies
are not specified, they are estimated from the parents' genotypes
(more information on this in the following sections).  The function
\texttt{trio()} then returns a list that contains the genotype
information in binary format, suitable as input for trio logic
regression: \texttt{bin} is a matrix with the conditional logistic
regression response in the first columns, and each SNP as two binary
variables using dominant and recessive coding. The list element \texttt{miss} contains
information about missing values in the original data, and
\texttt{freq} contains information on the estimated haplotype
frequencies.

%chunk3
<<>>=
trio.bin = trio(trio.dat=trio.tmp, blocks=c(1,4,2,3))
str(trio.bin, max=1)

trio.bin$bin[1:8,]
@ 

As mentioned above, the \texttt{trio} package also accommodates trio
genotype data.  The object \texttt{trio.gen1}, available in the R
package, is an example of such a data set. Equivalent to
\texttt{trio.ped1} used above, it contains information for 10 SNPs in
100 trios. When used in \texttt{trio.check()}, the argument
\texttt{is.linkage} is set to \texttt{FALSE}. The output from this
function is then identical to the one shown derived from the linkage
file, and can be passed to the function \texttt{trio()}.

%chunk4
<<>>=
data(trio.gen1)
str(trio.gen1)
trio.gen1[1:10,1:12]
trio.tmp = trio.check(dat=trio.gen1, is.linkage=F)
trio.bin = trio(trio.dat=trio.tmp, blocks=c(1,4,2,3))
@ 


\subsection*{Missing genotype information}

Missing genotypes in pedigree files are typically encoded using the
integer 0. The data files can be processed as before if they contain
such missing values:
%chunk5
<<>>=
data(trio.ped2)
str(trio.ped2)

trio.tmp = trio.check(dat=trio.ped2)
trio.tmp$trio[1:6,]
@ 

Since trio logic regression requires complete data, the function
\texttt{trio()} also performs an imputation of the missing
genotypes. The imputation is based on estimated haplotypes, using the
block length information specified by the user. In a later section we
demonstrate how this imputation can be run more efficiently when
haplotype frequency estimates are already available.

%chunk6
<<>>=
trio.bin = trio(trio.dat=trio.tmp, blocks=c(1,4,2,3))
trio.bin$bin[1:8,]
@ 

Missing data in genotypes files should be encoded using \texttt{NA},
the conventional symbol in R to indicate missing values.

%chunk7
<<>>=
data(trio.gen2)
str(trio.gen2)
trio.tmp = trio.check(dat=trio.gen2, is.linkage=F)
trio.bin = trio(trio.dat=trio.tmp, blocks=c(1,4,2,3))
trio.bin$bin[1:8,]
@


As the user might also be interested in the completed genotype data in
the original format (genotype or linkage file), the function
\texttt{trio()} also allows for this option by using the argument
\texttt{logic=F}. In the resulting object, the matrix \texttt{bin} is
then replaced by the data frame \texttt{trio}, and \texttt{miss} and
\texttt{freq} are also returned.

%chunk8
<<>>=
data(trio.gen2)
trio.tmp = trio.check(dat=trio.gen2, is.linkage=F)
trio.imp = trio(trio.dat=trio.tmp, blocks=c(1,4,2,3), logic=F)
str(trio.imp, max=1)
trio.imp$miss[c(1:6),]
print(trio.gen2[1:6,])
print(trio.imp$trio[1:6,])
@ 

The same applies to pedigree data:
%chunk9
<<>>=
data(trio.ped2)
trio.tmp = trio.check(dat=trio.ped2)
trio.imp = trio(trio.dat=trio.tmp, blocks=c(1,4,2,3), logic=F)
@ 


\subsection*{Mendelian errors}

To delineate the genotype information for the pseudo-controls, the
trio data must not contain any Mendelian errors. The function
\texttt{trio.check()} returns a warning, and an R object with relevant
information when Mendelian errors are encountered is created. 

%chunk10
<<>>=
data(trio.ped.err)
trio.tmp = trio.check(dat=trio.ped.err)
str(trio.tmp, max=1)
trio.tmp$errors
@ 

In this data set, trio 1 for example contains two Mendelian errors, in SNPs 9 and 10.

%chunk11
<<>>=
trio.tmp$trio.err[1:3, c(1,2, 11:12)]
trio.ped.err[1:3,c(1:2, 23:26)]
@ 

It is the user's responsibility to find the cause for the Mendelian
errors and correct those, if possible. However, Mendelian
inconsistencies are often due to genotyping errors and thus, it might
not be possible to correct those in a very straightforward manner. In
this instance, the user might want to encode the genotypes that cause
theses Mendelian errors in some of the trios as missing data. The
argument \texttt{replace=T} in \texttt{trio.check()} allows for this
possibility. The resulting missing data can then be imputed as
described in the previous section.

%chunk12
<<>>=
trio.rep = trio.check(dat=trio.ped.err, replace=T)
str(trio.rep, max=1)
trio.rep$trio[1:3,11:12]
@ 

The same option is available for data in genotype format with
Mendelian inconsistencies.

%chunk13
<<>>=
data(trio.gen.err)
trio.tmp = trio.check(dat=trio.gen.err, is.linkage=F)
trio.tmp$errors
trio.tmp$trio.err[1:6, c(1,2,7), drop=F]
trio.rep = trio.check(dat=trio.gen.err, is.linkage=F, replace=T)
trio.rep$trio[1:6,c(1,2,7)]
@ 

\subsection*{Using haplotype frequencies}

As mentioned above, when estimates for the haplotype frequencies are
already available, they can be used in the
imputation of missing data and the delineation of the
pseudo-controls. In case there are blocks of length one, i.~e., ~SNPs
not belonging to any LD blocks, the minor allele frequencies of those
SNPs are supplied. In this case, no haplotype estimation
is required when the function \texttt{trio} is run, which can result
in substantial time savings. 

As an example for the format of a file containing haplotype frequency
estimates and SNP minor allele frequencies, the object
\texttt{freq.hap} is available in the R package:

<<>>=
data(freq.hap)
str(freq.hap)
freq.hap[1:6,]
@ 

We can now impute the missing genotypes using these underlying haplotype frequencies.
<<>>=
data(trio.gen2)
trio.tmp = trio.check(dat=trio.gen2, is.linkage=F)
trio.imp = trio(trio.dat=trio.tmp, freq=freq.hap, logic=F)
str(trio.imp, max=1)
print(trio.gen2[1:6,])
print(trio.imp$trio[1:6,])
@


\section{Simulation}


The function \texttt{trio.sim()} simulates case-parents trio data when
the disease risk of children is specified by (possibly higher-order)
SNP-SNP interactions. The mating tables and the respective sampling
probabilities depend on the haplotype frequencies (or SNP minor allele
frequencies when the SNP does not belong to a block). This information
is specified in the \texttt{freq} argument of the function
\texttt{trio.sim()}. The probability of disease is assumed to be
described by the logistic term $\text{logit}(p) = \alpha + \beta
\times \text{Interaction}$, where $\alpha = \text{logit (\texttt{prev})}=\log(
\frac{\text{\texttt{prev}}}{1-\text{\texttt{prev}}} )$ and $\beta =
\log(\text{\texttt{OR}})$. The arguments \texttt{interaction, prev} and
\texttt{OR}, are specified in the function \texttt{trio.sim()}. Generating the mating tables and the
respective sampling probabilities, in particular for higher order
interactions, can be very CPU and memory intensive. We show how this
information, once it has been generated, can be used for future
simulations, and thus, speed up the simulations dramatically.


\subsection*{A basic example}

We use the built-in object \texttt{simuBkMap} in a basic example to
show how to simulate case-parent trios when the disease risk depends
on (possibly higher order) SNP-SNP interactions. This file contains
haplotype frequency information on 15 blocks with a total of 45 loci.
In this example, we specify that the children with two variant alleles
on SNP1 and two variant alleles on SNP5 have a higher disease risk. We
assume that \texttt{prev=0.001} and \texttt{OR=2} in the logistic model specifying
disease risk, and simulate a single replicate of 20 trios total. 


<<>>=
data(simuBkMap)
str(simuBkMap)
simuBkMap[1:7,]
sim = trio.sim(freq=simuBkMap, interaction="1R and 5R", prev=.001, OR=2, 
n=20, rep=1)
str(sim)
sim[[1]][1:6, 1:12]
@  



\subsection*{Using estimated haplotype frequencies}

In this example we estimate the haplotype frequencies in the built-in
data set \texttt{trio.gen1}, which contains genotypes for 10 SNPs
in 100 trios. These estimated frequencies are then used to simulate 20
trios for the above specified disease risk model.

<<>>=
data(trio.gen1)
trio.tmp = trio.check(dat=trio.gen1, is.linkage=F)
trio.impu = trio(trio.dat=trio.tmp, blocks=c(1, 4, 2, 3), logic=T)

str(trio.impu, max=2)
trio.impu$freq[1:7,]
sim = trio.sim(freq=trio.impu$freq, interaction="1R and 5R", prev=.001, OR=2, 
n=20, rep=1)

str(sim)
sim[[1]][1:6, ]
@

As before, the object containing the haplotype frequency information
can also be generated from external haplotype frequencies and SNP
minor allele frequencies. In
the following example we specify the haplotype frequencies, and generate two replicates of ten
trios each.

<<>>=
data(freq.hap)

sim = trio.sim(freq=freq.hap, interaction="1R or 4D", prev=.001, OR=2, 
n=10, rep=2)
str(sim)
sim[[1]][1:6,]
@ 


\subsection*{Using step-stones}

Generating the mating tables and the respective sampling probabilities
necessary to simulate case-parent trios can be very time consuming for
interaction models involving three or more SNPs. In simulation
studies, many replicates of similar data are usually required, and
generating these sampling probabilities in each instance would be a
large and avoidable computational burden (CPU and memory). The
sampling probabilities depend foremost on the interaction term and the
underlying haplotype frequencies, and as long as these remain constant
in the simulation study, the mating table information and the sampling
probabilities can be ``recycled.'' This is done by storing the
relevant information (denoted as ``step-stone'') as a binary R file in
the working directory, and loading the binary file again in future
simulations, speeding up the simulation process dramatically. It is
even possible to change the parameters \texttt{prev} and \texttt{OR} in these
additional simulations, as the sampling probabilities can be adjusted
accordingly.

In the following example, we first simulate case-parent trios using a
three-SNP interaction risk model, and save the step-stone object. We
then simulate additional trios with a different parameter \texttt{OR},
using the previously generated information.

<<>>=
data(freq.hap)

sim = trio.sim(freq=freq.hap, interaction="1R or (6R and 10D)", prev=.001, 
OR=2, n=10, rep=1)
str(sim)
sim[[1]][1:6,]
@ 

<<>>=
sim = trio.sim(freq=freq.hap, interaction="1R or (6R and 10D)", prev=.001, 
OR=3, n=10, rep=1, step.save="step3way")
str(sim, max=1)
sim[[1]][1:6,]
@ 

\section{Detection of LD blocks}\label{getLD}

This package also includes functions for the fast computation of the pairwise $D^\prime$ and $r^2$
values for hundreds or thousands of SNPs, and for the identification of LD blocks in these genotype
data using a modified version of the algorithm proposed by \citet{gabriel2002}. For the latter, it
is assumed that the SNPs are ordered by their position on the chromosomes.

The matrix \texttt{LDdata} available in

<<>>=
data(LDdata)
@ 

contains simulated genotype data for 10 LD blocks each consisting of 5 SNPs each typed on 500 subjects.

The pairwise $D^\prime$ and $r^2$ values can be computed by

<<>>=
ld.out <- getLD(LDdata, asMatrix=TRUE)
@ 

where by the default these values are stored in vectors to save memory. If \texttt{asMatrix} is set to \texttt{TRUE},
the values will be stored in matrices. The pairwise LD values for the first 10 SNPs (rounded to the second digit) can be displayed
by

<<>>=
round(ld.out$Dprime[1:10,1:10], 2)
@

<<>>=
round(ld.out$rSquare[1:10,1:10], 2)
@

and the pairwise LD plot for all SNPs can be generated by

\begin{figure}[!ht]
\centerline{\includegraphics[width=0.5\textwidth]{figure1}}
\caption{Pairwise $r^2$ values for the SNPs from \texttt{LDdata}.}\label{fig:1}
\end{figure} 

\begin{verbatim}
plot(ld.out)
\end{verbatim}
(see Figure \ref{fig:1}). This figure shows the $r^2$-values. The $D^\prime$ values can be plotted by

\begin{verbatim}
plot(ld.out, "Dprime")
\end{verbatim} 
(not shown).

The LD blocks in genotype data can be identified using the modified algorithm of \citet{gabriel2002}
by calling

<<>>=
blocks <- findLDblocks(LDdata)
blocks
@

Alternatively, the output of \texttt{getLD} can be used when \texttt{addVarN} has been set to \texttt{TRUE}
in \texttt{getLD} to store additional information on the pairwise LD values.

<<>>=
ld.out2 <- getLD(LDdata, addVarN=TRUE)
blocks2 <- findLDblocks(ld.out2)
blocks2
@

\begin{figure}[!b]
\centerline{\includegraphics[width=0.5\textwidth]{figure2}}
\caption{LD blocks as found by the modified algorithm of \citet{gabriel2002}. The borders of the LD blocks are marked
by red lines. The color for the LD between each pair of SNPs is defined by the three categories used by \citet{gabriel2002} 
to define the LD blocks.}\label{fig:2}
\end{figure} 


The blocks can also be plotted by

\begin{verbatim}
plot(blocks)
\end{verbatim}
(see Figure \ref{fig:2}). In this figure, the borders of the LD blocks are marked by red lines.
By default, the three categories used by the algorithm of \citet{gabriel2002} to define the LD blocks are
displayed. Since this algorithm is based on the $D^\prime$ values, it is also possible to show these values in
the LD (block) plot.

\begin{figure}[!b]
\centerline{\includegraphics[width=0.5\textwidth]{figure3}}
\vspace*{-8pt}
\caption{LD blocks as found by the modified algorithm of \citet{gabriel2002}. The borders of the LD blocks are marked
by red lines. The darker the field for each pair of SNPs, the larger is the $D^\prime$ value for the corresponding SNP pair.}\label{fig:3}
\end{figure} 


\begin{verbatim}
plot(blocks, "Dprime")
\end{verbatim}
(see Figure \ref{fig:3}). 

As mentioned in Section \ref{trio}, the haplotype structure required by \texttt{trio} can be obtained by

<<>>=
hap <- as.vector(table(blocks$blocks))
hap
@


\section*{Acknowledgments}
Support was provided by NIH grants R01 DK061662 and R01 HL090577, and by DFG grant SCHW 1508/1-1.

\clearpage
%\bibliography{xbib_appFinal}
%\bibliographystyle{mypapers}

\begin{thebibliography}{1}

\bibitem[{Gabriel et al.(2002)Gabriel, Schaffner, Nguyen, Moore,
  Roy, Blumenstiel, H., {DeFelice}, Lochner, Faggart, {Liu-Cordero}, Rotimi,
  Adeyemo, Cooper, Ward, Lander, Daly and Altshuler}]{gabriel2002}
\textsc{Gabriel, S.~B., Schaffner, S.~F., Nguyen, H., Moore, J.~M., Roy, J.,
  Blumenstiel, B., H., J., {DeFelice}, M., Lochner, A., Faggart, M.,
  {Liu-Cordero}, S.~N., Rotimi, C., Adeyemo, A., Cooper, R., Ward, R., Lander,
  E.~S., Daly, M.~J. and Altshuler, D.} (2002). The structure of haplotype
  blocks in the human genome. \emph{Science} \textbf{296}, 2225--2229.
\end{thebibliography}

\end{document}



